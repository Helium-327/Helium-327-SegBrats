# -*- coding: UTF-8 -*-
'''

ä»£ç è¯´æ˜:    è®­ç»ƒæµç¨‹

Created on      2024/07/23 15:28:23
Author:         @Mr_Robot
State:          loss å¯ä»¥æ­£å¸¸ä¸‹é™ï¼Œéœ€è¦è¿›è¡Œæ•°æ®å¢å¼º
TODO:          1. æ·»åŠ æ—©åœç­–ç•¥
'''

import os
import time
import torch
import readline # è§£å†³input()æ— æ³•ä½¿ç”¨Backspaceçš„é—®é¢˜, ä¸èƒ½åˆ æ‰
from tabulate import tabulate
from torch.utils.tensorboard import SummaryWriter

from train_and_val import train_one_epoch, val_one_epoch
from utils.log_writer import custom_logger
from utils.ckpt_save_load import save_checkpoint, load_checkpoint
from nets.unet3ds import *
from utils.get_commits import *


os.environ["CUDA_LAUNCH_BLOCKING"] = '1'
torch.backends.cudnn.benchmark = True
torch.backends.cudnn.deterministic = True

# constant
RANDOM_SEED = 42
DEVICE = torch.device("cuda:0" if torch.cuda.is_available() else "cpu")



date_time_str = get_current_date() + ' ' + get_current_time()
def train(model, Metrics, train_loader, val_loader, scaler, optimizer, scheduler, loss_function, num_epochs, device, results_dir, logs_path, start_epoch, best_val_loss, tb=False,  interval=10, save_loss_threshold=0.4):
    """
    æ¨¡å‹è®­ç»ƒæµç¨‹
    :param model: æ¨¡å‹
    :param train_loader: è®­ç»ƒæ•°æ®é›†
    :param val_loader: éªŒè¯æ•°æ®é›†
    :param optimizer: ä¼˜åŒ–å™¨
    :param loss_function: åˆç§° criterion æŸå¤±å‡½æ•°
    :param num_epochs: è®­ç»ƒè½®æ•°
    :param device: è®¾å¤‡
    """
    best_epoch = 0
    end_epoch = start_epoch + num_epochs
    model_name = model.__class__.__name__
    optimizer_name = optimizer.__class__.__name__
    scheduler_name = scheduler.__class__.__name__
    loss_func_name = loss_function.__class__.__name__
    tb_dir = os.path.join(results_dir, f'tensorBoard/{model_name}_braTS21_{date_time_str}')
    ckpt_dir = os.path.join(results_dir, f'checkpoints/{model_name}_braTS21_{date_time_str}')
    os.makedirs(ckpt_dir, exist_ok=True)
    writer = SummaryWriter(tb_dir)
        
    
    for epoch in range(start_epoch, end_epoch):
        
        # =============================== è®­ç»ƒè¿‡ç¨‹ ===============================
        print(f"=== Training on [Epoch {epoch+1}/{end_epoch}] ===:")
        
        train_mean_loss = 0.0
        start_time = time.time()
        # è®­ç»ƒ
        train_running_loss, train_et_loss, train_tc_loss, train_wt_loss = train_one_epoch(model, train_loader, scaler, optimizer, loss_function, device)
        
        # è®¡ç®—å¹³å‡loss
        train_mean_loss =  train_running_loss / len(train_loader) 
        mean_train_et_loss = train_et_loss / len(train_loader)
        mean_train_tc_loss = train_tc_loss / len(train_loader)
        mean_train_wt_loss = train_wt_loss / len(train_loader)
        
        # scheduler.step(train_mean_loss)
        writer.add_scalars('train/DiceLoss',
                           {'Mean':train_mean_loss, 
                            'ET': mean_train_et_loss, 
                            'TC': mean_train_tc_loss, 
                            'WT': mean_train_wt_loss}, epoch)
        end_time = time.time()
        train_cost_time = end_time - start_time
        # print info
        print(f"- Train mean loss: {train_mean_loss:.4f}\n"
              f"- ET loss: {mean_train_et_loss:.4f}\n"
              f"- TC loss: {mean_train_tc_loss:.4f}\n"
              f"- WT loss: {mean_train_wt_loss:.4f}\n"
              f"- Cost time: {train_cost_time/60:.2f}mins â±ï¸\n")
        
        # =============================== éªŒè¯è¿‡ç¨‹ ===============================
        if (epoch+1) % interval == 0:
            print(f"=== Validating on [Epoch {epoch+1}/{end_epoch}] ===:")
            
            # å¼€å§‹è®¡æ—¶
            start_time = time.time()
            
            # éªŒè¯
            val_running_loss, val_et_loss, val_tc_loss, val_wt_loss, Metrics_list= val_one_epoch(model, Metrics, val_loader, loss_function, epoch, device)
            
            # è®¡ç®—å¹³å‡loss
            val_mean_loss = val_running_loss / len(val_loader)
            mean_val_et_loss = val_et_loss / len(val_loader)
            mean_val_tc_loss = val_tc_loss / len(val_loader)
            mean_val_wt_loss = val_wt_loss / len(val_loader)
            scheduler.step(val_mean_loss)
            
            
            # è®°å½•éªŒè¯ç»“æœ
            val_scores = {}
            val_scores['epoch'] = epoch
            val_scores['Dice_scores'] = Metrics_list[0] 
            val_scores['Jaccard_scores'] = Metrics_list[1]
            val_scores['Accuracy_scores'] = Metrics_list[2]
            val_scores['Precision_scores'] = Metrics_list[3]
            val_scores['Recall_scores'] = Metrics_list[4]
            val_scores['F1_scores'] = Metrics_list[5]
            val_scores['F2_scores'] = Metrics_list[6]
            # val_metrics.append(val_scores)
            
            # è®°å½•è®­ç»ƒç»“æœ
            # tensorboardè®°å½•éªŒè¯ç»“æœ
            if tb: 
                writer.add_scalars('val/DiceLoss', 
                                {'Mean':val_mean_loss, 
                                    'ET': mean_val_et_loss, 
                                    'TC': mean_val_tc_loss, 
                                    'WT': mean_val_wt_loss},
                                epoch)

                writer.add_scalars('val/Dice_coeff',
                                {'Mean':val_scores['Dice_scores'][0],
                                    'ET': val_scores['Dice_scores'][1],
                                    'TC': val_scores['Dice_scores'][2],
                                    'WT': val_scores['Dice_scores'][3]},
                                epoch)

                writer.add_scalars('val/Jaccard_index',
                                {'Mean':val_scores['Jaccard_scores'][0],
                                    'ET': val_scores['Jaccard_scores'][1],
                                    'TC': val_scores['Jaccard_scores'][2],
                                    'WT': val_scores['Jaccard_scores'][3]},
                                epoch)   

                writer.add_scalars('val/Accuracy',
                                {'Mean':val_scores['Accuracy_scores'][0],
                                    'ET': val_scores['Accuracy_scores'][1],
                                    'TC': val_scores['Accuracy_scores'][2],
                                    'WT': val_scores['Accuracy_scores'][3]},
                                epoch)
                
                writer.add_scalars('val/Precision', 
                                {'Mean':val_scores['Precision_scores'][0],
                                    'ET': val_scores['Precision_scores'][1], 
                                    'TC': val_scores['Precision_scores'][2], 
                                    'WT': val_scores['Precision_scores'][3]},
                                epoch)
                
                writer.add_scalars('val/Recall', 
                                {'Mean':val_scores['Recall_scores'][0], 
                                    'ET': val_scores['Recall_scores'][1], 
                                    'TC': val_scores['Recall_scores'][2], 
                                    'WT': val_scores['Recall_scores'][3]},
                                epoch)
                writer.add_scalars('val/F1', 
                                {'Mean':val_scores['F1_scores'][0], 
                                    'ET': val_scores['F1_scores'][1], 
                                    'TC': val_scores['F1_scores'][2], 
                                    'WT': val_scores['F1_scores'][3]},
                                epoch) 
                writer.add_scalars('val/F2', 
                                {'Mean':val_scores['F2_scores'][0], 
                                    'ET': val_scores['F2_scores'][1], 
                                    'TC': val_scores['F2_scores'][2], 
                                    'WT': val_scores['F2_scores'][3]},
                                epoch)                               
            
            end_time = time.time()
            val_cost_time = end_time - start_time


            
            """-------------------------------------- æ‰“å°æŒ‡æ ‡ --------------------------------------------------"""
            metric_table_header = ["Metric_Name", "MEAN", "ET", "TC", "WT"]
            metric_table_left = ["Dice", "Jaccard", "Accuracy", "Precision", "Recall", "F1", "F2"]
            val_info_str =f" ===  Epoch {epoch} ===\n"\
                            f"- Model:{model_name}\n"\
                            f"- Optimizer:{optimizer_name}\n"\
                            f"- Scheduler:{scheduler_name}\n"\
                            f"- LossFunc:{loss_func_name}\n"\
                            f"- Lr:{scheduler.get_last_lr()[0]:.6f}\n"\
                            f"- val_cost_time:{val_cost_time:.4f}s â±ï¸\n"

            # ä¼˜åŒ–ç‚¹ï¼šç›´æ¥é€šè¿‡æ˜ å°„è·å–æŒ‡æ ‡åç§°ï¼Œé¿å…é‡å¤å­—ç¬¦ä¸²æ ¼å¼åŒ–
            def format_value(value, decimals=4):
                # è¿”å›ä¸€ä¸ªæ ¼å¼åŒ–åçš„å­—ç¬¦ä¸²ï¼Œä¿ç•™æŒ‡å®šçš„å°æ•°ä½æ•°
                return f"{value:.{decimals}f}"
            
            metric_scores_mapping = {metric: val_scores[f"{metric}_scores"] for metric in metric_table_left}
            metric_table = [[metric,
                            format_value(metric_scores_mapping[metric][0]),
                            format_value(metric_scores_mapping[metric][1]),
                            format_value(metric_scores_mapping[metric][2]),
                            format_value(metric_scores_mapping[metric][3])] for metric in metric_table_left]
            loss_str = f"Mean Loss: {val_mean_loss:.4f}, ET: {mean_val_et_loss:.4f}, TC: {mean_val_tc_loss:.4f}, WT: {mean_val_wt_loss:.4f}\n"
            table_str = tabulate(metric_table, headers=metric_table_header, tablefmt='grid')
            metrics_info = val_info_str + table_str + '\n' + loss_str  
            
            # å°†æŒ‡æ ‡è¡¨æ ¼å†™å…¥æ—¥å¿—æ–‡ä»¶
            custom_logger(metrics_info, logs_path)
            print(metrics_info)
            
            """------------------------------------- ä¿å­˜æƒé‡æ–‡ä»¶ --------------------------------------------"""
            last_ckpt_path = os.path.join(ckpt_dir, f'{model_name}_braTS21_{loss_func_name}_{date_time_str}_{epoch}_{val_mean_loss:.4f}.pth')
            
            if val_mean_loss < best_val_loss:
                best_val_loss = val_mean_loss
                best_epoch = epoch
                with open(os.path.join(os.path.dirname(logs_path), "current_log.txt"), 'a') as f:
                    f.write(f"=== EPOCH {best_epoch} ===:\n"\
                            f"@ {date_time_str}\n"\
                            f"current lr : {scheduler.get_last_lr()[0]:.6f}\n"\
                            f"loss: Mean:{val_mean_loss:.4f}\t ET: {mean_val_et_loss:.4f}\t TC: {mean_val_tc_loss:.4f}\t WT: {mean_val_wt_loss:.4f}\n"
                            f"mean dice : {val_scores['Dice_scores'][0]:.4f}\t" \
                            f"ET : {val_scores['Dice_scores'][1]:.4f}\t"\
                            f"TC : {val_scores['Dice_scores'][2]:.4f}\t" \
                            f"WT : {val_scores['Dice_scores'][3]:.4f}\n\n")
                
                if best_val_loss < save_loss_threshold: # æŸå¤±å°äº0.5æ—¶ä¿å­˜æ¨¡å‹
                    save_checkpoint(model, optimizer, scaler, best_epoch, best_val_loss, last_ckpt_path)
                
    print(f"ğŸ˜ƒğŸ˜ƒğŸ˜ƒTrain finished. Best val loss: ğŸ‘‰{best_val_loss:.4f} at epoch {best_epoch+1}")
    # è®­ç»ƒå®Œæˆåå…³é—­ SummaryWriter
    writer.close() 
    



