{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.nn import functional as F"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 基于UNet3d进行改进"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. 网络结构"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DoubleConv(nn.Module):\n",
    "    def __init__(self, in_channels, out_channels):\n",
    "        super(DoubleConv, self).__init__()\n",
    "        self.conv = nn.Sequential(\n",
    "            nn.Conv3d(in_channels, out_channels, kernel_size=3, padding=1),\n",
    "            nn.BatchNorm3d(out_channels),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Conv3d(out_channels, out_channels, kernel_size=3, padding=1),\n",
    "            nn.BatchNorm3d(out_channels),\n",
    "            nn.ReLU(inplace=True)\n",
    "         )\n",
    "    def forward(self, x):\n",
    "        return self.conv(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.1 UNet_BN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class UNet3d_bn(nn.Module):\n",
    "    def __init__(self, in_channels, out_channels):\n",
    "        super(UNet3d_bn, self).__init__()\n",
    "        self.encoder1 = DoubleConv(in_channels, 32)\n",
    "        self.encoder2 = DoubleConv(32, 64)\n",
    "        self.encoder3 = DoubleConv(64, 128)\n",
    "        self.encoder4 = DoubleConv(128, 256)\n",
    "        self.encoder5 = DoubleConv(256, 512) \n",
    "\n",
    "        self.decoder1 = DoubleConv(512, 256)\n",
    "        self.conv_trans1 = nn.ConvTranspose3d(512, 256, kernel_size=2, stride=2)\n",
    "        self.decoder2 = DoubleConv(256, 128)\n",
    "        self.conv_trans2 = nn.ConvTranspose3d(256, 128, kernel_size=2, stride=2)\n",
    "        self.decoder3 = DoubleConv(128, 64)\n",
    "        self.conv_trans3 = nn.ConvTranspose3d(128, 64, kernel_size=2, stride=2)\n",
    "        self.decoder4 = DoubleConv(64, 32)\n",
    "        self.conv_trans4 = nn.ConvTranspose3d(64, 32, kernel_size=2, stride=2)\n",
    "        self.out_conv = DoubleConv(32, out_channels)\n",
    "\n",
    "        self.soft = nn.Softmax(dim=1)\n",
    "        \n",
    "        \n",
    "    def forward(self, x):\n",
    "        # 编码器部分\n",
    "        t1 = self.encoder1(x)                                               # 32 x 128 x 128 x 128\n",
    "        out = F.max_pool3d(t1, 2, 2)                                        # 32 x 64 x 64 x 64\n",
    "                                    \n",
    "        t2 = self.encoder2(out)                                             # 64 x 64 x 64 x 64\n",
    "        out = F.max_pool3d(t2, 2, 2)                                        # 64 x 32 x 32 x 32\n",
    "        \n",
    "        t3 = self.encoder3(out)                                             # 128 x 32 x 32 x 32\n",
    "        out = F.max_pool3d(t3, 2, 2)                                        # 128 x 16 x 16 x 16\n",
    "        \n",
    "        t4 = self.encoder4(out)                                             # 256 x 16 x 16 x 16\n",
    "        out = F.max_pool3d(t4, 2, 2)                                        # 256 x 8 x 8 x 8\n",
    "        \n",
    "        out = self.encoder5(out)                                            # 512 x 8 x 8 x 8\n",
    "        \n",
    "        \n",
    "        \n",
    "        out = self.conv_trans1(out)                                         # 256 x 16 x 16 x 16\n",
    "        out = self.decoder1(torch.cat([out, t4], dim=1))                    # 256 x 16 x 16 x 16\n",
    "        \n",
    "        out = self.conv_trans2(out)                                          # 128 x 32 x 32 x 32\n",
    "        out = self.decoder2(torch.cat([out, t3], dim=1))                    # 128 x 32 x 32 x 32\n",
    "        \n",
    "        out = self.conv_trans3(out)                                         # 64 x 64 x 64 x 64\n",
    "        out = self.decoder3(torch.cat([out, t2], dim=1))                    # 64 x 64 x 64 x 64                \n",
    "\n",
    "        out = self.conv_trans4(out)                                         # 32 x 128 x 128 x 128\n",
    "        out = self.decoder4(torch.cat([out, t1], dim=1))                    # 32 x 128 x 128 x 128\n",
    "\n",
    "        out = self.out_conv(out)                                            # out_channels x 128 x 128\n",
    "        \n",
    "        out = self.soft(out)                                             # softmax\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 4, 128, 128, 128])\n",
      "----------------------------------------------------------------\n",
      "        Layer (type)               Output Shape         Param #\n",
      "================================================================\n",
      "            Conv3d-1    [-1, 32, 128, 128, 128]           3,488\n",
      "            Conv3d-2       [-1, 64, 64, 64, 64]          55,360\n",
      "            Conv3d-3      [-1, 128, 32, 32, 32]         221,312\n",
      "            Conv3d-4      [-1, 256, 16, 16, 16]         884,992\n",
      "            Conv3d-5         [-1, 512, 8, 8, 8]       3,539,456\n",
      "   ConvTranspose3d-6      [-1, 256, 16, 16, 16]       1,048,832\n",
      "            Conv3d-7      [-1, 256, 16, 16, 16]       3,539,200\n",
      "   ConvTranspose3d-8      [-1, 128, 32, 32, 32]         262,272\n",
      "            Conv3d-9      [-1, 128, 32, 32, 32]         884,864\n",
      "  ConvTranspose3d-10       [-1, 64, 64, 64, 64]          65,600\n",
      "           Conv3d-11       [-1, 64, 64, 64, 64]         221,248\n",
      "  ConvTranspose3d-12    [-1, 32, 128, 128, 128]          16,416\n",
      "           Conv3d-13    [-1, 32, 128, 128, 128]          55,328\n",
      "           Conv3d-14     [-1, 4, 128, 128, 128]           3,460\n",
      "      BatchNorm3d-15     [-1, 4, 128, 128, 128]               8\n",
      "             ReLU-16     [-1, 4, 128, 128, 128]               0\n",
      "           Conv3d-17     [-1, 4, 128, 128, 128]             436\n",
      "      BatchNorm3d-18     [-1, 4, 128, 128, 128]               8\n",
      "             ReLU-19     [-1, 4, 128, 128, 128]               0\n",
      "       DoubleConv-20     [-1, 4, 128, 128, 128]               0\n",
      "          Softmax-21     [-1, 4, 128, 128, 128]               0\n",
      "================================================================\n",
      "Total params: 10,802,280\n",
      "Trainable params: 10,802,280\n",
      "Non-trainable params: 0\n",
      "----------------------------------------------------------------\n",
      "Input size (MB): 32.00\n",
      "Forward/backward pass size (MB): 2554.00\n",
      "Params size (MB): 41.21\n",
      "Estimated Total Size (MB): 2627.21\n",
      "----------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "from torchsummary import summary\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model = UNet3d_bn(in_channels=4, out_channels=4)\n",
    "input_tensor = torch.randn([1, 4, 128, 128, 128]).float()\n",
    "\n",
    "model.to(device)\n",
    "input_tensor = input_tensor.to(device)\n",
    "\n",
    "\n",
    "out = model(input_tensor)\n",
    "print(out.shape)\n",
    "summary(model, (4, 128, 128, 128))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# simple UNet3d_ln\n",
    "class UNet3d_ln(nn.Module):\n",
    "    def __init__(self, in_channels, out_channels):\n",
    "        super(UNet3d_ln, self).__init__()\n",
    "        self.encoder1 = nn.Conv3d(in_channels, 32, kernel_size=3, padding=1)\n",
    "        self.encoder2 = nn.Conv3d(32, 64, kernel_size=3, padding=1)\n",
    "        self.encoder3 = nn.Conv3d(64, 128, kernel_size=3, padding=1)\n",
    "        self.encoder4 = nn.Conv3d(128, 256, kernel_size=3, padding=1)\n",
    "        self.encoder5 = nn.Conv3d(256, 512, kernel_size=3, padding=1)\n",
    "\n",
    "        self.decoder1 = nn.Conv3d(512, 256, kernel_size=3, padding=1)\n",
    "        self.conv_trans1 = nn.ConvTranspose3d(512, 256, kernel_size=2, stride=2)\n",
    "        self.decoder2 = nn.Conv3d(256, 128, kernel_size=3, padding=1)\n",
    "        self.conv_trans2 = nn.ConvTranspose3d(256, 128, kernel_size=2, stride=2)\n",
    "        self.decoder3 = nn.Conv3d(128, 64, kernel_size=3, padding=1)\n",
    "        self.conv_trans3 = nn.ConvTranspose3d(128, 64, kernel_size=2, stride=2)\n",
    "        self.decoder4 = nn.Conv3d(64, 32, kernel_size=3, padding=1)\n",
    "        self.conv_trans4 = nn.ConvTranspose3d(64, 32, kernel_size=2, stride=2)\n",
    "        self.out_conv = nn.Conv3d(32, out_channels, kernel_size=3, padding=1)\n",
    "\n",
    "        self.soft = nn.Softmax(dim=1)\n",
    "        \n",
    "        \n",
    "    def forward(self, x):\n",
    "        # 编码器\n",
    "        out = self.encoder1(x)                                              # 32 x 128 x 128 x 128\n",
    "        out = F.relu(F.layer_norm(out, out.shape[-3:]))                     \n",
    "        t1 = out                                                            # 32 x 128 x 128 x 128\n",
    "        \n",
    "        out = F.max_pool3d(t1, 2, 2)                                        # 32 x 64 x 64 x 64\n",
    "        out = self.encoder2(out)                                            # 64 x 64 x 64 x 64\n",
    "        out = F.relu(F.layer_norm(out, out.shape[-3:]))\n",
    "        t2 = out                                                            # 64 x 64 x 64 x 64\n",
    "\n",
    "        out = F.max_pool3d(t2, 2, 2)                                        # 64 x 32 x 32 x 32\n",
    "        out = self.encoder3(out)                                            # 128 x 32 x 32 x 32\n",
    "        out = F.relu(F.layer_norm(out, out.shape[-3:]))\n",
    "        t3 = out                                                            # 128 x 32 x 32 x 32\n",
    "\n",
    "        out = F.max_pool3d(t3, 2, 2)                                        # 128 x 16 x 16 x 16\n",
    "        out = self.encoder4(out)                                            # 256 x 16 x 16 x 16\n",
    "        out = F.relu(F.layer_norm(out, out.shape[-3:]))                     \n",
    "        t4 = out                                                            # 256 x 16 x 16 x 16\n",
    "        \n",
    "        out = F.max_pool3d(t4, 2, 2)                                        # 256 x 8 x 8 x 8\n",
    "        out = self.encoder5(out)                                            # 512 x 8 x 8 x 8\n",
    "        out = F.relu(F.layer_norm(out, out.shape[-3:]))\n",
    "        \n",
    "        # 解码器\n",
    "        out = self.conv_trans1(out)                                         # 256 x 16 x 16 x 16\n",
    "        out = self.decoder1(torch.cat([out, t4], dim=1))                    # 256 x 16 x 16 x 16\n",
    "        out = F.relu(F.layer_norm(out, out.shape[-3:]))\n",
    "        \n",
    "        out = self.conv_trans2(out)                                         # 128 x 32 x 32 x 32\n",
    "        out = self.decoder2(torch.cat([out, t3], dim=1))                    # 128 x 32 x 32 x 32\n",
    "        out = F.relu(F.layer_norm(out, out.shape[-3:]))\n",
    "\n",
    "        out = self.conv_trans3(out)                                         # 64 x 64 x 64 x 64\n",
    "        out = self.decoder3(torch.cat([out, t2], dim=1))                    # 64 x 64 x 64 x 64\n",
    "        out = F.relu(F.layer_norm(out, out.shape[-3:]))                 \n",
    "        \n",
    "        out = self.conv_trans4(out)                                         # 32 x 128 x 128 x 128\n",
    "        out = self.decoder4(torch.cat([out, t1], dim=1))                    # 32 x 128 x 128 x 128\n",
    "        out = F.relu(F.layer_norm(out, out.shape[-3:]))                     \n",
    "        \n",
    "        out = self.out_conv(out)                                            # out_channels x 128 x 128 x 128\n",
    "        \n",
    "        out = self.soft(out)                                                # softmax\n",
    "        \n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# 改进\n",
    "class UNet3d_ln_double(nn.Module):\n",
    "    def __init__(self, in_channels, out_channels):\n",
    "        super(UNet3d_ln_double, self).__init__()\n",
    "        self.encoder1 = nn.Conv3d(in_channels, 32, kernel_size=3, padding=1)\n",
    "        self.encoder2 = nn.Conv3d(32, 64, kernel_size=3, padding=1)\n",
    "        self.encoder3 = nn.Conv3d(64, 128, kernel_size=3, padding=1)\n",
    "        self.encoder4 = nn.Conv3d(128, 256, kernel_size=3, padding=1)\n",
    "        self.encoder5 = nn.Conv3d(256, 512, kernel_size=3, padding=1)\n",
    "\n",
    "        self.conv_32    = nn.Conv3d(32, 32, kernel_size=3, padding=1)\n",
    "        self.conv_64    = nn.Conv3d(64, 64, kernel_size=3, padding=1)\n",
    "        self.conv_128    = nn.Conv3d(128, 128, kernel_size=3, padding=1)\n",
    "        self.conv_256    = nn.Conv3d(256, 256, kernel_size=3, padding=1)\n",
    "        self.conv_512    = nn.Conv3d(512, 512, kernel_size=3, padding=1)    \n",
    "        \n",
    "        self.decoder1 = nn.Conv3d(512, 256, kernel_size=3, padding=1)\n",
    "        self.conv_trans1 = nn.ConvTranspose3d(512, 256, kernel_size=2, stride=2)\n",
    "        self.decoder2 = nn.Conv3d(256, 128, kernel_size=3, padding=1)\n",
    "        self.conv_trans2 = nn.ConvTranspose3d(256, 128, kernel_size=2, stride=2)\n",
    "        self.decoder3 = nn.Conv3d(128, 64, kernel_size=3, padding=1)\n",
    "        self.conv_trans3 = nn.ConvTranspose3d(128, 64, kernel_size=2, stride=2)\n",
    "        self.decoder4 = nn.Conv3d(64, 32, kernel_size=3, padding=1)\n",
    "        self.conv_trans4 = nn.ConvTranspose3d(64, 32, kernel_size=2, stride=2)\n",
    "        self.out_conv = nn.Conv3d(32, out_channels, kernel_size=3, padding=1)\n",
    "\n",
    "        self.soft = nn.Softmax(dim=1)\n",
    "        \n",
    "        \n",
    "        \n",
    "    def forward(self, x):\n",
    "        # 编码器\n",
    "        out = self.encoder1(x)                                              # 32 x 128 x 128 x 128\n",
    "        out = F.relu(F.layer_norm(out, out.shape[-3:]))                     \n",
    "        out = self.conv_32(out)\n",
    "        out = F.relu(F.layer_norm(out, out.shape[-3:]))\n",
    "        t1 = out                                                            # 32 x 128 x 128 x 128\n",
    "        \n",
    "        out = F.max_pool3d(t1, 2, 2)                                        # 32 x 64 x 64 x 64\n",
    "        out = self.encoder2(out)                                            # 64 x 64 x 64 x 64\n",
    "        out = F.relu(F.layer_norm(out, out.shape[-3:]))\n",
    "        out = self.conv_64(out)\n",
    "        out = F.relu(F.layer_norm(out, out.shape[-3:]))\n",
    "        t2 = out                                                            # 64 x 64 x 64 x 64\n",
    "\n",
    "        out = F.max_pool3d(t2, 2, 2)                                        # 64 x 32 x 32 x 32\n",
    "        out = self.encoder3(out)                                            # 128 x 32 x 32 x 32\n",
    "        out = F.relu(F.layer_norm(out, out.shape[-3:]))\n",
    "        out = self.conv_128(out)\n",
    "        out = F.relu(F.layer_norm(out, out.shape[-3:]))\n",
    "        t3 = out                                                            # 128 x 32 x 32 x 32\n",
    "\n",
    "        out = F.max_pool3d(t3, 2, 2)                                        # 128 x 16 x 16 x 16\n",
    "        out = self.encoder4(out)                                            # 256 x 16 x 16 x 16\n",
    "        out = F.relu(F.layer_norm(out, out.shape[-3:]))                     \n",
    "        out = self.conv_256(out)\n",
    "        out = F.relu(F.layer_norm(out, out.shape[-3:]))\n",
    "        t4 = out                                                            # 256 x 16 x 16 x 16\n",
    "        \n",
    "        out = F.max_pool3d(t4, 2, 2)                                        # 256 x 8 x 8 x 8\n",
    "        out = self.encoder5(out)                                            # 512 x 8 x 8 x 8\n",
    "        out = F.relu(F.layer_norm(out, out.shape[-3:]))\n",
    "        out = self.conv_512(out)\n",
    "        out = F.relu(F.layer_norm(out, out.shape[-3:]))\n",
    "        \n",
    "        # 解码器\n",
    "        out = self.conv_trans1(out)                                         # 256 x 16 x 16 x 16\n",
    "        out = self.decoder1(torch.cat([out, t4], dim=1))                    # 256 x 16 x 16 x 16\n",
    "        out = F.relu(F.layer_norm(out, out.shape[-3:]))\n",
    "        out = self.conv_256(out)\n",
    "        out = F.relu(F.layer_norm(out, out.shape[-3:]))\n",
    "        \n",
    "        out = self.conv_trans2(out)                                         # 128 x 32 x 32 x 32\n",
    "        out = self.decoder2(torch.cat([out, t3], dim=1))                    # 128 x 32 x 32 x 32\n",
    "        out = F.relu(F.layer_norm(out, out.shape[-3:]))\n",
    "        out = self.conv_128(out)\n",
    "        out = F.relu(F.layer_norm(out, out.shape[-3:]))\n",
    "\n",
    "        out = self.conv_trans3(out)                                         # 64 x 64 x 64 x 64\n",
    "        out = self.decoder3(torch.cat([out, t2], dim=1))                    # 64 x 64 x 64 x 64\n",
    "        out = F.relu(F.layer_norm(out, out.shape[-3:]))                 \n",
    "        out = self.conv_64(out)\n",
    "        out = F.relu(F.layer_norm(out, out.shape[-3:]))\n",
    "        \n",
    "        out = self.conv_trans4(out)                                         # 32 x 128 x 128 x 128\n",
    "        out = self.decoder4(torch.cat([out, t1], dim=1))                    # 32 x 128 x 128 x 128\n",
    "        out = F.relu(F.layer_norm(out, out.shape[-3:]))                     \n",
    "        out = self.conv_32(out)\n",
    "        out = F.relu(F.layer_norm(out, out.shape[-3:]))\n",
    "        \n",
    "        out = self.out_conv(out)                                            # out_channels x 128 x 128 x 128\n",
    "        \n",
    "        out = self.soft(out)                                                # softmax\n",
    "        \n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 4, 128, 128, 128])\n",
      "----------------------------------------------------------------\n",
      "        Layer (type)               Output Shape         Param #\n",
      "================================================================\n",
      "            Conv3d-1    [-1, 32, 128, 128, 128]           3,488\n",
      "            Conv3d-2       [-1, 64, 64, 64, 64]          55,360\n",
      "            Conv3d-3      [-1, 128, 32, 32, 32]         221,312\n",
      "            Conv3d-4      [-1, 256, 16, 16, 16]         884,992\n",
      "            Conv3d-5         [-1, 512, 8, 8, 8]       3,539,456\n",
      "   ConvTranspose3d-6      [-1, 256, 16, 16, 16]       1,048,832\n",
      "            Conv3d-7      [-1, 256, 16, 16, 16]       3,539,200\n",
      "   ConvTranspose3d-8      [-1, 128, 32, 32, 32]         262,272\n",
      "            Conv3d-9      [-1, 128, 32, 32, 32]         884,864\n",
      "  ConvTranspose3d-10       [-1, 64, 64, 64, 64]          65,600\n",
      "           Conv3d-11       [-1, 64, 64, 64, 64]         221,248\n",
      "  ConvTranspose3d-12    [-1, 32, 128, 128, 128]          16,416\n",
      "           Conv3d-13    [-1, 32, 128, 128, 128]          55,328\n",
      "           Conv3d-14     [-1, 4, 128, 128, 128]           3,460\n",
      "          Softmax-15     [-1, 4, 128, 128, 128]               0\n",
      "================================================================\n",
      "Total params: 10,801,828\n",
      "Trainable params: 10,801,828\n",
      "Non-trainable params: 0\n",
      "----------------------------------------------------------------\n",
      "Input size (MB): 32.00\n",
      "Forward/backward pass size (MB): 2170.00\n",
      "Params size (MB): 41.21\n",
      "Estimated Total Size (MB): 2243.21\n",
      "----------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "from torchsummary import summary\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model = UNet3d_ln(in_channels=4, out_channels=4)\n",
    "input_tensor = torch.randn([1, 4, 128, 128, 128]).float()\n",
    "\n",
    "model.to(device)\n",
    "input_tensor = input_tensor.to(device)\n",
    "\n",
    "\n",
    "out = model(input_tensor)\n",
    "print(out.shape)\n",
    "summary(model, (4, 128, 128, 128))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 4, 128, 128, 128])\n",
      "----------------------------------------------------------------\n",
      "        Layer (type)               Output Shape         Param #\n",
      "================================================================\n",
      "            Conv3d-1    [-1, 32, 128, 128, 128]           3,488\n",
      "            Conv3d-2    [-1, 32, 128, 128, 128]          27,680\n",
      "            Conv3d-3       [-1, 64, 64, 64, 64]          55,360\n",
      "            Conv3d-4       [-1, 64, 64, 64, 64]         110,656\n",
      "            Conv3d-5      [-1, 128, 32, 32, 32]         221,312\n",
      "            Conv3d-6      [-1, 128, 32, 32, 32]         442,496\n",
      "            Conv3d-7      [-1, 256, 16, 16, 16]         884,992\n",
      "            Conv3d-8      [-1, 256, 16, 16, 16]       1,769,728\n",
      "            Conv3d-9         [-1, 512, 8, 8, 8]       3,539,456\n",
      "           Conv3d-10         [-1, 512, 8, 8, 8]       7,078,400\n",
      "  ConvTranspose3d-11      [-1, 256, 16, 16, 16]       1,048,832\n",
      "           Conv3d-12      [-1, 256, 16, 16, 16]       3,539,200\n",
      "           Conv3d-13      [-1, 256, 16, 16, 16]       1,769,728\n",
      "  ConvTranspose3d-14      [-1, 128, 32, 32, 32]         262,272\n",
      "           Conv3d-15      [-1, 128, 32, 32, 32]         884,864\n",
      "           Conv3d-16      [-1, 128, 32, 32, 32]         442,496\n",
      "  ConvTranspose3d-17       [-1, 64, 64, 64, 64]          65,600\n",
      "           Conv3d-18       [-1, 64, 64, 64, 64]         221,248\n",
      "           Conv3d-19       [-1, 64, 64, 64, 64]         110,656\n",
      "  ConvTranspose3d-20    [-1, 32, 128, 128, 128]          16,416\n",
      "           Conv3d-21    [-1, 32, 128, 128, 128]          55,328\n",
      "           Conv3d-22    [-1, 32, 128, 128, 128]          27,680\n",
      "           Conv3d-23     [-1, 4, 128, 128, 128]           3,460\n",
      "          Softmax-24     [-1, 4, 128, 128, 128]               0\n",
      "================================================================\n",
      "Total params: 22,581,348\n",
      "Trainable params: 22,581,348\n",
      "Non-trainable params: 0\n",
      "----------------------------------------------------------------\n",
      "Input size (MB): 32.00\n",
      "Forward/backward pass size (MB): 3532.00\n",
      "Params size (MB): 86.14\n",
      "Estimated Total Size (MB): 3650.14\n",
      "----------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "from torchsummary import summary\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model = UNet3d_ln_double(in_channels=4, out_channels=4)\n",
    "input_tensor = torch.randn([1, 4, 128, 128, 128]).float()\n",
    "\n",
    "model.to(device)\n",
    "input_tensor = input_tensor.to(device)\n",
    "\n",
    "\n",
    "out = model(input_tensor)\n",
    "print(out.shape)\n",
    "summary(model, (4, 128, 128, 128))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "ename": "TclError",
     "evalue": "invalid command name \".!text\"",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTclError\u001b[0m                                  Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[4], line 62\u001b[0m\n\u001b[1;32m     59\u001b[0m     write_readme(experiment_dir, experiment_content)\n\u001b[1;32m     61\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;18m__name__\u001b[39m \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m__main__\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[0;32m---> 62\u001b[0m     \u001b[43mmain\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[4], line 53\u001b[0m, in \u001b[0;36mmain\u001b[0;34m()\u001b[0m\n\u001b[1;32m     51\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mmain\u001b[39m():\n\u001b[1;32m     52\u001b[0m     \u001b[38;5;66;03m# 获取实验内容\u001b[39;00m\n\u001b[0;32m---> 53\u001b[0m     experiment_content \u001b[38;5;241m=\u001b[39m \u001b[43mget_experiment_content\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     55\u001b[0m     \u001b[38;5;66;03m# 创建实验结果目录\u001b[39;00m\n\u001b[1;32m     56\u001b[0m     experiment_dir \u001b[38;5;241m=\u001b[39m create_experiment_dir()\n",
      "Cell \u001b[0;32mIn[4], line 49\u001b[0m, in \u001b[0;36mget_experiment_content\u001b[0;34m()\u001b[0m\n\u001b[1;32m     46\u001b[0m \u001b[38;5;66;03m# 显示弹窗\u001b[39;00m\n\u001b[1;32m     47\u001b[0m windows\u001b[38;5;241m.\u001b[39mmainloop()\n\u001b[0;32m---> 49\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mconfirm\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[4], line 39\u001b[0m, in \u001b[0;36mget_experiment_content.<locals>.confirm\u001b[0;34m()\u001b[0m\n\u001b[1;32m     38\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mconfirm\u001b[39m():\n\u001b[0;32m---> 39\u001b[0m     experiment_content \u001b[38;5;241m=\u001b[39m \u001b[43mentry\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m1.0\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtk\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mEND\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     40\u001b[0m     windows\u001b[38;5;241m.\u001b[39mdestroy()\n\u001b[1;32m     41\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m experiment_content\n",
      "File \u001b[0;32m~/miniconda3/envs/cv/lib/python3.10/tkinter/__init__.py:3750\u001b[0m, in \u001b[0;36mText.get\u001b[0;34m(self, index1, index2)\u001b[0m\n\u001b[1;32m   3748\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mget\u001b[39m(\u001b[38;5;28mself\u001b[39m, index1, index2\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[1;32m   3749\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Return the text from INDEX1 to INDEX2 (not included).\"\"\"\u001b[39;00m\n\u001b[0;32m-> 3750\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtk\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcall\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_w\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mget\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mindex1\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mindex2\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mTclError\u001b[0m: invalid command name \".!text\""
     ]
    }
   ],
   "source": [
    "import os\n",
    "import datetime\n",
    "import tkinter as tk\n",
    "\n",
    "def create_experiment_dir():\n",
    "    # 获取当前时间\n",
    "    current_time = datetime.datetime.now().strftime(\"%Y-%m-%d-%H-%M-%S\")\n",
    "    \n",
    "    # 创建results文件夹\n",
    "    results_dir = \"results\"\n",
    "    if not os.path.exists(results_dir):\n",
    "        os.makedirs(results_dir)\n",
    "    \n",
    "    # 创建实验结果目录\n",
    "    experiment_dir = os.path.join(results_dir, current_time)\n",
    "    os.makedirs(experiment_dir)\n",
    "    \n",
    "    return experiment_dir\n",
    "\n",
    "def write_readme(experiment_dir, experiment_content):\n",
    "    # 创建README.md文件\n",
    "    readme_file = os.path.join(experiment_dir, \"README.md\")\n",
    "    with open(readme_file, \"w\") as f:\n",
    "        f.write(experiment_content)\n",
    "\n",
    "def get_experiment_content():\n",
    "    # 创建弹窗\n",
    "    windows = tk.Tk()\n",
    "    windows.title(\"Experiment Content\")\n",
    "    \n",
    "    # 创建输入框\n",
    "    label = tk.Label(windows, text=\"input experiment content:\")\n",
    "    label.pack()\n",
    "    entry = tk.Text(windows, height=10, width=40)\n",
    "    entry.pack()\n",
    "    \n",
    "    # 创建确定按钮\n",
    "    def confirm():\n",
    "        experiment_content = entry.get(\"1.0\", tk.END)\n",
    "        windows.destroy()\n",
    "        return experiment_content\n",
    "    \n",
    "    button = tk.Button(windows, text=\"confirm\", command=lambda: confirm())\n",
    "    button.pack()\n",
    "    \n",
    "    # 显示弹窗\n",
    "    windows.mainloop()\n",
    "    \n",
    "    return confirm()\n",
    "\n",
    "def main():\n",
    "    # 获取实验内容\n",
    "    experiment_content = get_experiment_content()\n",
    "    \n",
    "    # 创建实验结果目录\n",
    "    experiment_dir = create_experiment_dir()\n",
    "    \n",
    "    # 写入README.md文件\n",
    "    write_readme(experiment_dir, experiment_content)\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "cv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
